#app/services/llm_service.py
from typing import Any, Dict, List, Optional
import logging
import re
import google.generativeai as genai
import json

from app.config import settings
from app.schemas import BadgeStatus, PolicySearchRequest
from app.models import Policy, Scholarship, ScholarshipLLMCache, User
from sqlalchemy.orm import Session

logger = logging.getLogger(__name__)

if settings.google_api_key:
    genai.configure(api_key=settings.google_api_key)


class LLMService:
    # =========================
    # ‚úÖ Scholarships: very-light personalization (no LLM)
    # =========================
    @staticmethod
    def evaluate_scholarship_user_fit(
        user: User,
        scholarship: Scholarship,
        card_json: Optional[Dict[str, Any]] = None,
    ) -> Dict[str, Any]:
        """
        Ïû•ÌïôÍ∏à Í∞úÏù∏ÎßûÏ∂§ÏùÑ "Îπ°Îπ°ÌïòÏßÄ ÏïäÍ≤å" ÌåêÎã®.
        - PASS: ÏÇ¨Ïö©Ïûê Ï†ïÎ≥¥Î°ú Î¥§ÏùÑ Îïå Í∏çÏ†ï ÏãúÍ∑∏ÎÑêÏù¥ ÏûàÍ≥†, Î™ÖÎ∞±Ìïú Ï∂©ÎèåÏù¥ ÏóÜÏùå
        - FAIL: Í±∞Ïùò ÏóÜÏùå(Î™ÖÎ∞±Ìïú Ï∂©ÎèåÏùº ÎïåÎßå)  ‚Üê Í∏∞Î≥∏ÏùÄ WARNING
        - WARNING: Ï†ïÎ≥¥ Î∂ÄÏ°±/Ïï†Îß§

        Î∞òÌôò:
        {
          "user_fit": "PASS"|"WARNING"|"FAIL",
          "user_fit_reason": str|None,
          "missing_info": [str, ...]
        }
        """
        missing: List[str] = []
        reasons: List[str] = []

        # 1) ÌïôÏÉù Ïó¨Î∂Ä: Ïû•ÌïôÍ∏àÏùÄ Í∏∞Î≥∏Ï†ÅÏúºÎ°ú ÌïôÏÉù ÎåÄÏÉÅÏù¥ ÎßéÏúºÎãà,
        #    is_studentÍ∞Ä FalseÎ©¥ WARNING(ÎòêÎäî ÌäπÏ†ï ÏºÄÏù¥Ïä§Î©¥ FAIL) Ï†ïÎèÑÎ°úÎßå.
        if user.is_student is None:
            missing.append("ÌïôÏÉù Ïó¨Î∂Ä")
        elif user.is_student is False:
            # "Ïû¨ÌïôÏÉù" Ï†ÑÏö©Ïù¥ÎùºÍ≥† Î™ÖÎ∞±Ìûà Ïì∞Ïù∏ Í≤ΩÏö∞Îßå FAILÎ°ú ÎßåÎì§Í≥†,
            # ÎÇòÎ®∏ÏßÄÎäî WARNINGÎ°ú ÎëîÎã§(Îπ°Îπ°ÌïòÍ≤å Ïïà Í∞ÄÍ∏∞).
            text = " ".join(
                [
                    scholarship.selection_criteria or "",
                    scholarship.retention_condition or "",
                    (card_json or {}).get("one_liner") or "",
                    " ".join((card_json or {}).get("eligibility_bullets") or []),
                ]
            )
            if any(k in text for k in ["Ïû¨ÌïôÏÉù", "Ïû¨Ìïô", "Ïû¨Ìïô Ï§ë", "Ïû¨ÌïôÏûê"]):
                return {
                    "user_fit": "FAIL",
                    "user_fit_reason": "Ïû¨ÌïôÏÉù ÎåÄÏÉÅ Ïû•ÌïôÍ∏àÏúºÎ°ú Î≥¥Ïù¥ÎäîÎç∞, ÌòÑÏû¨ ÌïôÏÉùÏù¥ ÏïÑÎãå Í≤ÉÏúºÎ°ú ÏÑ§Ï†ïÎêòÏñ¥ ÏûàÏñ¥Ïöî.",
                    "missing_info": [],
                }
            reasons.append("ÌïôÏÉùÏù¥ ÏïÑÎãàÏñ¥ÎèÑ ÏßÄÏõê Í∞ÄÎä•ÌïúÏßÄ ÌôïÏù∏Ïù¥ ÌïÑÏöîÌï¥Ïöî")

        # 2) Ï†ÑÍ≥µ/ÌïôÎÖÑ: ÏûàÏúºÎ©¥ Ïù¥Ïú†ÏóêÎßå Î∞òÏòÅ(Îß§Ïπ≠ÏùÑ Îπ°Îπ°ÌïòÍ≤å ÌïòÏßÄ ÏïäÏùå)
        if not user.major:
            missing.append("Ï†ÑÍ≥µ")
        else:
            reasons.append("Ï†ÑÍ≥µ Ï†ïÎ≥¥Î•º Ï∞∏Í≥†ÌñàÏñ¥Ïöî")

        if user.grade is None:
            missing.append("ÌïôÎÖÑ")
        else:
            reasons.append("ÌïôÎÖÑ Ï†ïÎ≥¥Î•º Ï∞∏Í≥†ÌñàÏñ¥Ïöî")

        # 3) ÌïôÏ†ê(GPA): Ïπ¥ÎìúÏóêÏÑú gpa_minÏù¥ ÏûàÏùÑ ÎïåÎßå ÎπÑÍµê
        gpa_min = None
        if isinstance(card_json, dict):
            gm = card_json.get("gpa_min")
            if isinstance(gm, (int, float)):
                gpa_min = float(gm)

        if user.gpa is None:
            if gpa_min is not None:
                missing.append("ÌèâÏ†ê(GPA)")
        else:
            # gpa_minÏù¥ ÏûàÏúºÎ©¥ ÎπÑÍµêÌïòÎêò, ÎØ∏Îã¨Ïù¥ÎùºÍ≥† FAILÍπåÏßÄÎäî Ïûò Ïïà ÎÇ¥Î¶º(Îπ°Îπ°ÌïòÏßÄ ÏïäÍ≤å)
            if gpa_min is not None:
                if float(user.gpa) >= gpa_min:
                    reasons.append(f"ÌèâÏ†ê({user.gpa})Ïù¥ ÏµúÏÜå Í∏∞Ï§Ä({gpa_min}) Ïù¥ÏÉÅÏù¥ÏóêÏöî")
                else:
                    reasons.append(f"ÌèâÏ†ê({user.gpa})Ïù¥ ÏµúÏÜå Í∏∞Ï§Ä({gpa_min})Ïóê Î™ª ÎØ∏Ïπ† Ïàò ÏûàÏñ¥Ïöî")

        # 4) ÏµúÏ¢Ö user_fit Í≤∞Ï†ï (ÏùòÎèÑÏóê ÎßûÍ≤å Ï†ïÎ¶¨)
        # - FAILÏùÄ ÏúÑÏóêÏÑú Ïù¥ÎØ∏ return
        # - missing_infoÍ∞Ä ÏûàÏúºÎ©¥ WARNING
        # - Î™ÖÎ∞±Ìïú Ï∂©ÎèåÏùÄ ÏóÜÍ≥†, Í∏çÏ†ï ÏãúÍ∑∏ÎÑêÏù¥ ÏûàÏúºÎ©∞ missingÏù¥ ÏóÜÏùÑ ÎïåÎßå PASS

        if missing:
            user_fit = "WARNING"
        elif reasons:
            user_fit = "PASS"
        else:
            user_fit = "WARNING"

        return {
            "user_fit": user_fit,
            "user_fit_reason": " ¬∑ ".join(reasons) if reasons else None,
            "missing_info": missing,
        }
    @staticmethod
    def _fallback_summary(
        req: PolicySearchRequest,
        policy: Policy,
    ) -> Dict[str, Any]:
        """
        GOOGLE_API_KEY ÎØ∏ÏÑ§Ï†ï / LLM Ïò§Î•ò Ïãú ÏÇ¨Ïö©ÌïòÎäî Í∑úÏπô Í∏∞Î∞ò ÏöîÏïΩ.
        - region / category / age Î≤îÏúÑÎ•º Ï°∞Ìï©Ìï¥ÏÑú Ìïú Ï§Ñ ÏöîÏïΩ Î¨∏Ïû•ÏùÑ ÎßåÎì†Îã§.
        - Î±ÉÏßÄÎäî ÏùºÎã® WARNINGÏúºÎ°ú Í≥†Ï†ï (ÎÇòÏ§ëÏóê Î£∞ÏùÑ Î∞îÍøîÎèÑ Îê®).
        """
        parts: list[str] = []

        # ÏßÄÏó≠
        if policy.region:
            parts.append(policy.region)

        # ÎåÄÎ∂ÑÎ•ò(Ï∑®ÏóÖ¬∑ÏùºÏûêÎ¶¨ / ÏÜåÎìù¬∑ÏÉùÌôú Îì±)
        if policy.category:
            parts.append(policy.category)

        # ÎÇòÏù¥ Î≤îÏúÑ
        age_str = None
        if policy.age_min is not None and policy.age_max is not None:
            age_str = f"{policy.age_min}~{policy.age_max}ÏÑ∏"
        elif policy.age_min is not None:
            age_str = f"{policy.age_min}ÏÑ∏ Ïù¥ÏÉÅ"
        elif policy.age_max is not None:
            age_str = f"{policy.age_max}ÏÑ∏ Ïù¥Ìïò"

        if age_str:
            parts.append(age_str)

        meta = " ¬∑ ".join(parts) if parts else "Ï≤≠ÎÖÑ Ï†ïÏ±Ö"

        short_summary = f"{meta} ÎåÄÏÉÅÏùò '{policy.title}' ÏßÄÏõêÏÇ¨ÏóÖÏûÖÎãàÎã§."

        return {
            "badge_status": BadgeStatus.WARNING.value,
            "short_summary": short_summary,
            "reason": "LLM ÎπÑÌôúÏÑ±Ìôî ÏÉÅÌÉú ÎòêÎäî Ìò∏Ï∂ú Ïã§Ìå® (Î£∞ Í∏∞Î∞ò ÏöîÏïΩ)",
            "missing_criteria": [],
        }
    @staticmethod
    def _postprocess_badge(
        parsed: Dict[str, Any],
        policy: Policy,
        req: PolicySearchRequest,
    ) -> Dict[str, Any]:
        """
        GeminiÍ∞Ä Ï§Ä badge_statusÎ•º Í∑∏ÎåÄÎ°ú Ïì∞ÏßÄ ÏïäÍ≥†,
        ÏÇ¨ÎûåÏù¥ Î≥¥Í∏∞ Îçî ÏûêÏó∞Ïä§ÎüΩÍ≤å Ìïú Î≤à Î≥¥Ï†ïÌïòÎäî Îã®Í≥Ñ.

        - FAILÏù∏Îç∞ 'Ï†ïÎ≥¥ Î∂ÄÏ°± / ÌåêÎã® Î∂àÍ∞Ä' Í≥ÑÏó¥Ïù¥Î©¥ WARNINGÏúºÎ°ú ÏôÑÌôî
        - Í∞ïÌïú Î∂ÄÏ†ï Î¨∏Íµ¨Í∞Ä Ï†ÑÌòÄ ÏóÜÎäîÎç∞ FAILÏù¥Î©¥ WARNINGÏúºÎ°ú ÏôÑÌôî
        """
        badge = (parsed.get("badge_status") or "").upper()
        reason = (parsed.get("reason") or "").strip()
        summary = (parsed.get("short_summary") or "").strip()

        # üîé 1) Ï†ïÎ≥¥ Î∂ÄÏ°± / ÌåêÎã® Î∂àÍ∞Ä Ìå®ÌÑ¥Îì§
        info_lack_keywords = [
            "ÌåêÎã®Ìï† Ïàò ÏóÜ",
            "ÌåêÎã®ÌïòÍ∏∞ Ïñ¥Î†µ",
            "ÌåêÎã®Ìï† Ïàò ÏóÜÏñ¥",
            "Ï†ïÎ≥¥Í∞Ä ÏóÜÏñ¥",
            "Ï†ïÎ≥¥Í∞Ä Î∂ÄÏ°±",
            "Î∂ÄÏ°±ÌïòÏó¨",
            "Ï∂îÍ∞Ä Ï†ïÎ≥¥",
        ]

        # üîé 2) ÏßÑÏßú 'ÏôÑÏ†Ñ ÌÉàÎùΩ' ÎäêÎÇåÏùò Í∞ïÌïú Î∂ÄÏ†ï Ìå®ÌÑ¥Îì§
        strong_fail_keywords = [
            "Ïã†Ï≤≠Ìï† Ïàò ÏóÜ",
            "Ïã†Ï≤≠Ìï† Ïàò ÏóÜÏäµÎãàÎã§",
            "ÎåÄÏÉÅÏù¥ ÏïÑÎãôÎãàÎã§",
            "ÏßÄÏõê ÎåÄÏÉÅÏù¥ ÏïÑÎãôÎãàÎã§",
            "Ìï¥ÎãπÎêòÏßÄ ÏïäÏäµÎãàÎã§",
            "Ï†úÏô∏Îê©ÎãàÎã§",
        ]

        # ‚ù∂ FAILÏù∏ Í≤ΩÏö∞ ‚Üí Ï†ïÎ≥¥ Î∂ÄÏ°±Ïù¥Î©¥ WARNINGÏúºÎ°ú ÏôÑÌôî
        if badge == "FAIL":
            # (1) Ï†ïÎ≥¥ Î∂ÄÏ°± Í≥ÑÏó¥Ïù¥Î©¥ ‚Üí WARNINGÏúºÎ°ú ÏôÑÌôî
            if any(k in reason for k in info_lack_keywords):
                parsed["badge_status"] = BadgeStatus.WARNING.value
                return parsed

            # (2) Í∞ïÌïú Î∂ÄÏ†ï Î¨∏Íµ¨Í∞Ä ÌïòÎÇòÎèÑ ÏóÜÏúºÎ©¥ ‚Üí WARNINGÏúºÎ°ú ÏôÑÌôî
            if not any(k in reason for k in strong_fail_keywords):
                parsed["badge_status"] = BadgeStatus.WARNING.value
                return parsed

        # ‚ù∑ WARNINGÏù∏Îç∞, Î¨∏Íµ¨Í∞Ä ÎÑàÎ¨¥ Í∞ïÌïòÍ≤å "ÏôÑÏ†Ñ ÌÉàÎùΩ"Ïù¥Î©¥ ‚Üí FAILÎ°ú Í≤©ÏÉÅ
        if badge == "WARNING":
            text_for_check = reason + " " + summary
            if any(k in text_for_check for k in strong_fail_keywords):
                parsed["badge_status"] = BadgeStatus.FAIL.value
                return parsed
        # ÎÇòÎ®∏ÏßÄÎäî Í∑∏ÎåÄÎ°ú Î∞òÌôò
        return parsed
    @staticmethod
    def _build_fast_track_prompt(
        req: PolicySearchRequest,
        policy: Policy,
    ) -> str:
        age_part = f"{req.age}ÏÑ∏" if req.age is not None else "ÎÇòÏù¥ Ï†ïÎ≥¥ ÏóÜÏùå"
        region_part = req.region or "ÏßÄÏó≠ Ï†ïÎ≥¥ ÏóÜÏùå"

        # Ï†ïÏ±Ö ÏõêÎ¨∏ ÌÖçÏä§Ìä∏ Íµ¨ÏÑ±:
        # 1ÏàúÏúÑ: policy.raw_text
        # 2ÏàúÏúÑ: raw_snippet + raw_expln + raw_support Ï°∞Ìï©
        text_source = policy.raw_text

        if not text_source:
            pieces: list[str] = []
            for attr in ("raw_snippet", "raw_expln", "raw_support"):
                v = getattr(policy, attr, None)
                if v:
                    pieces.append(str(v))
            text_source = " ".join(pieces)

        text = text_source or ""
        if len(text) > 6000:
            text = text[:6000]

        prompt = (
            "Îã§ÏùåÏùÄ ÎåÄÌïúÎØºÍµ≠ Ï≤≠ÎÖÑ ÏßÄÏõê Ï†ïÏ±ÖÏùò ÏõêÎ¨∏ ÏùºÎ∂ÄÏù¥Îã§.\n"
            "Ï£ºÏñ¥ÏßÑ ÏÇ¨Ïö©ÏûêÏùò ÎÇòÏù¥ÏôÄ ÏßÄÏó≠ Ï†ïÎ≥¥Î•º Í∏∞Ï§ÄÏúºÎ°ú Ïù¥ Ï†ïÏ±ÖÏùò Ïã†Ï≤≠ Í∞ÄÎä•ÏÑ±ÏùÑ ÌèâÍ∞ÄÌïòÎùº.\n\n"
            "‚ö†Ô∏è ÌåêÎã® ÏõêÏπô(Îß§Ïö∞ Ï§ëÏöî):\n"
            "1. Ï†ïÏ±Ö ÏõêÎ¨∏ ÎòêÎäî Î©îÌÉÄ Ï†ïÎ≥¥Ïóê **Î™ÖÏãúÏ†ÅÏúºÎ°ú ÎåÄÏÉÅÏù¥ ÏïÑÎãò**Ïù¥ ÎìúÎü¨ÎÇòÏßÄ ÏïäÎäî Ìïú FAILÎ°ú ÌåêÎã®ÌïòÏßÄ Îßê Í≤É.\n"
            "2. Ï†ïÎ≥¥Í∞Ä Î∂ÄÏ°±ÌïòÍ±∞ÎÇò Ï°∞Í±¥Ïù¥ Ïï†Îß§Ìïú Í≤ΩÏö∞ÏóêÎäî Î∞òÎìúÏãú WARNINGÏúºÎ°ú ÌåêÎã®Ìï† Í≤É.\n"
            "3. Ï†ïÏ±Ö ÏõêÎ¨∏Ïóê ÏûêÍ≤© ÏöîÍ±¥Ïù¥ ÏóÜÏùÑ Í≤ΩÏö∞, ÏïÑÎûò Ï†úÍ≥µÎêú Ï†ïÏ±Ö Î©îÌÉÄ Ï†ïÎ≥¥(age/region)Î•º Í∑ºÍ±∞Î°ú Í∞ÄÎä•ÏÑ±ÏùÑ Ï∂îÏ†ïÌï† Í≤É.\n"
            "4. FAILÏùÄ Îã§ÏùåÍ≥º Í∞ôÏùÄ Í≤ΩÏö∞ÏóêÎßå ÏÇ¨Ïö©ÌïúÎã§:\n"
            "   - Ïó∞Î†π Ï¥àÍ≥º/ÎØ∏Îã¨Ïù¥ Î™ÖÌôïÌï®\n"
            "   - Í±∞Ï£º ÏßÄÏó≠Ïù¥ Î™ÖÌôïÌûà Î∂àÏùºÏπòÌï®\n"
            "   - Ï†ïÏ±Ö ÏõêÎ¨∏Ïóê 'ÏßÄÏõê ÎåÄÏÉÅÏù¥ ÏïÑÎãò', 'Ïã†Ï≤≠ Î∂àÍ∞Ä'Í∞Ä Î™ÖÏãúÎê®\n\n"
            "ÏùëÎãµ ÌòïÏãùÏùÄ Î∞òÎìúÏãú JSON Ìïú Ï§ÑÎ°úÎßå Ï∂úÎ†•ÌïúÎã§.\n"
            '{\n'
            '  "badge_status": "PASS" | "WARNING" | "FAIL",\n'
            '  "short_summary": "ÏÇ¨Ïö©Ïûê Í¥ÄÏ†êÏùò Ìïú Î¨∏Ïû• ÏöîÏïΩ",\n'
            '  "reason": "ÌåêÎã® Í∑ºÍ±∞Î•º Í∞ÑÎã®Ìûà ÏÑ§Î™Ö",\n'
            '  "missing_criteria": ["Î∂ÄÏ°±Ìïú Ï°∞Í±¥Ïù¥ ÏûàÎã§Î©¥ ÎÇòÏó¥"]\n'
            "}\n\n"
            f"[ÏÇ¨Ïö©Ïûê Ï†ïÎ≥¥]\n"
            f"- ÎÇòÏù¥: {age_part}\n"
            f"- ÏßÄÏó≠: {region_part}\n\n"
            f"[Ï†ïÏ±Ö Î©îÌÉÄ Ï†ïÎ≥¥]\n"
            f"- Ï†ïÏ±Ö ÏßÄÏó≠(meta): {policy.region}\n"
            f"- Ïó∞Î†π Î≤îÏúÑ(meta): {policy.age_min} ~ {policy.age_max}\n"
            f"- Ï†ïÏ±Ö Î∂ÑÏïº(meta): {policy.category}\n\n"
            f"[Ï†ïÏ±Ö Ï†úÎ™©]\n"
            f"{policy.title}\n\n"
            f"[Ï†ïÏ±Ö ÏõêÎ¨∏ ÏùºÎ∂Ä]\n"
            f"{text}\n"
        )
        return prompt

    @staticmethod
    def _parse_fast_track_result(raw: str) -> Dict[str, Any]:
        import json
        # 0) ÏõêÎ≥∏ Î¨∏ÏûêÏó¥ Ï†ïÎ¶¨
        s = raw.strip()

        # 1) ```json ... ``` Í∞ôÏùÄ ÎßàÌÅ¨Îã§Ïö¥ ÏΩîÎìúÎ∏îÎ°ùÏù¥Î©¥ Î≤óÍ≤®ÎÇ¥Í∏∞
        if s.startswith("```"):
            # Ï≤´ Ï§Ñ(Ïòà: ```json) Ï†úÍ±∞
            first_newline = s.find("\n")
            if first_newline != -1:
                s = s[first_newline + 1 :]
            # ÎßàÏßÄÎßâÏùò ``` Ï†úÍ±∞
            if s.endswith("```"):
                s = s[:-3]
            s = s.strip()

        # 2) ÌòπÏãú ÏïûÎí§Ïóê Îã§Î•∏ ÌÖçÏä§Ìä∏Í∞Ä ÏÑûÏó¨ ÏûàÏñ¥ÎèÑ,
        #    Í∞ÄÏû• Î∞îÍπ• Ï™ΩÏùò { ... } Î≤îÏúÑÎßå ÏûòÎùºÎÇ¥Í∏∞
        if "{" in s and "}" in s:
            start = s.find("{")
            end = s.rfind("}")
            if start != -1 and end != -1 and end > start:
                s = s[start : end + 1]

        try:
            return json.loads(s)
        except Exception as e:
            # üî• Ïó¨Í∏∞ÏÑú LLMÏù¥ Î≥¥ÎÇ∏(Ï†ïÎ¶¨Îêú) ÏõêÎ¨∏ ÏùºÎ∂ÄÎ•º Î°úÍ∑∏Î°ú Ï∞çÏñ¥Î≥¥Ïûê
            logger.warning(
                "[LLMService] FastTrack JSON ÌååÏã± Ïã§Ìå® (%s): raw=%r",
                e.__class__.__name__,
                s[:300],  # ÎÑàÎ¨¥ Í∏∏Î©¥ ÏûòÎùºÏÑú
            )
            return {
                "badge_status": "WARNING",
                "short_summary": "Ï†ïÏ±Ö ÏöîÏïΩÏóê Ïã§Ìå®ÌñàÏäµÎãàÎã§.",
                "reason": "LLM ÏùëÎãµ ÌååÏã± Ïã§Ìå®",
                "missing_criteria": [],
            }

    @staticmethod
    def evaluate_eligibility(
        req: PolicySearchRequest,
        policy: Policy,
    ) -> Dict[str, Any]:
        """
        Fast TrackÏóêÏÑú Í∞Å Ï†ïÏ±ÖÎ≥ÑÎ°ú PASS/WARNING/FAIL Î±ÉÏßÄÏôÄ ÏöîÏïΩÏùÑ ÎßåÎìúÎäî Ìï®Ïàò.
        - GOOGLE_API_KEY ÏóÜÏúºÎ©¥: Î∞îÎ°ú ÎçîÎØ∏ Í≤∞Í≥º
        - LLM Ìò∏Ï∂ú Ï§ë ÏóêÎü¨ ÎÇòÎ©¥: ÎçîÎØ∏ Í≤∞Í≥º + ÏóêÎü¨ Ï†ïÎ≥¥ ÏÇ¥Ïßù Ìè¨Ìï®
        """
        # 1) ÌÇ§Í∞Ä ÏïÑÏòà ÏóÜÏúºÎ©¥: Í∑úÏπô Í∏∞Î∞ò Í∞ÑÎã® ÏöîÏïΩ
        if not settings.google_api_key:
            logger.warning("[LLMService] GOOGLE_API_KEY ÎØ∏ÏÑ§Ï†ï ‚Üí fallback ÏÇ¨Ïö©")
            return LLMService._fallback_summary(req, policy)

        prompt = LLMService._build_fast_track_prompt(req, policy)

        try:
            # üîÅ Ïó¨Í∏∞ Î™®Îç∏ Ïù¥Î¶ÑÏùÄ ÌôòÍ≤ΩÏóê ÎßûÍ≤å ÎÇòÏ§ëÏóê Ï°∞Ï†ï Í∞ÄÎä•
            logger.info("[LLMService] Gemini FastTrack Ìò∏Ï∂ú ÏãúÏûë (policy_id=%s)", policy.id)
            model = genai.GenerativeModel("gemini-2.5-flash-lite")
            response = model.generate_content(prompt)
            raw_text = response.text or ""
            logger.debug("[LLMService] Gemini raw ÏùëÎãµ ÏùºÎ∂Ä: %r", raw_text[:200])

            parsed = LLMService._parse_fast_track_result(raw_text)
            # üîß LLMÏù¥ Ï§Ä badgeÎ•º ÏÇ¨ÎûåÏù¥ Î≥¥Í∏∞ Ï¢ãÍ≤å Ìïú Î≤à ÌõÑÏ≤òÎ¶¨
            parsed = LLMService._postprocess_badge(parsed, policy, req)

            # üî• ÌååÏã±ÏùÄ ÎêêÎäîÎç∞, Ïó¨Ï†ÑÌûà Ïö∞Î¶¨Í∞Ä Ï†ïÏùòÌïú 'Ïã§Ìå® Î©îÏãúÏßÄ'Î©¥ ‚Üí fallbackÏúºÎ°ú ÎåÄÏ≤¥
            if parsed.get("short_summary") == "Ï†ïÏ±Ö ÏöîÏïΩÏóê Ïã§Ìå®ÌñàÏäµÎãàÎã§.":
                logger.info(
                    "[LLMService] LLM ÌååÏã± Í≤∞Í≥ºÍ∞Ä Ïã§Ìå® Í∏∞Î≥∏Í∞í ‚Üí fallback ÏöîÏïΩ ÏÇ¨Ïö© (policy_id=%s)",
                    policy.id,
                )
                return LLMService._fallback_summary(req, policy)

            return parsed

        except Exception as e:
            # LLM Ìò∏Ï∂ú Ïã§Ìå®Ìï¥ÎèÑ FastAPIÎäî 500 Ïïà ÎÇ¥Í≥†, Í∑úÏπô Í∏∞Î∞ò ÏöîÏïΩ ÏÇ¨Ïö©
            logger.error(
                "[LLMService] Gemini Ìò∏Ï∂ú ÏòàÏô∏ Î∞úÏÉù ‚Üí fallback ÏÇ¨Ïö© (%s: %s)",
                e.__class__.__name__,
                str(e),
            )
            fallback = LLMService._fallback_summary(req, policy)
            fallback["reason"] = f"LLM Ìò∏Ï∂ú Ïã§Ìå®: {e.__class__.__name__}"
            return fallback

    # ===== Deep TrackÏóêÏÑú ÏÇ¨Ïö©Ìï† Ï∂îÏ∂úÏö© =====
    @staticmethod
    def build_deep_track_prompt(page_texts: List[str]) -> str:
        combined = "\n\n---\n\n".join(page_texts)
        if len(combined) > 12000:
            combined = combined[:12000]

        prompt = (
            "Îã§ÏùåÏùÄ ÌäπÏ†ï Ï≤≠ÎÖÑ Ï†ïÏ±Ö ÌéòÏù¥ÏßÄÏóêÏÑú ÏàòÏßëÌïú ÌÖçÏä§Ìä∏Ïù¥Îã§.\n"
            "Ïù¥ ÌÖçÏä§Ìä∏Î•º Î∞îÌÉïÏúºÎ°ú Ïã†Ï≤≠ ÏûêÍ≤©/ÎåÄÏÉÅ/Í∏∞Í∞Ñ/ÌïÑÏàò ÏÑúÎ•ò Îì± Ï§ëÏöîÌïú Ï°∞Í±¥ÏùÑ Íµ¨Ï°∞ÌôîÌï¥Îùº.\n\n"
            "ÏùëÎãµ ÌòïÏãùÏùÄ Î∞òÎìúÏãú JSON Ìïú Ï§ÑÎ°úÎßå Ï∂úÎ†•ÌïúÎã§.\n"
            "{\n"
            '  "criteria": {\n'
            '    "age": "Ïòà: Îßå 19~34ÏÑ∏",\n'
            '    "region": "Ïòà: ÏÑúÏö∏ Í±∞Ï£º",\n'
            '    "employment": "Ïòà: ÎØ∏Ï∑®ÏóÖ ÎòêÎäî ÌîÑÎ¶¨ÎûúÏÑú",\n'
            '    "others": ["Í∏∞ÌÉÄ Ï°∞Í±¥1", "Í∏∞ÌÉÄ Ï°∞Í±¥2", ...]\n'
            "  },\n"
            '  "evidence_text": "Í∞ÄÏû• ÌïµÏã¨Ï†ÅÏù∏ Î∂ÄÎ∂ÑÎßå Î∞úÏ∑åÌïú ÏöîÏïΩ ÌÖçÏä§Ìä∏"\n'
            "}\n\n"
            "Îã§ÏùåÏùÄ ÏàòÏßëÎêú ÏõêÎ¨∏Ïù¥Îã§:\n"
            f"{combined}\n"
        )
        return prompt

    @staticmethod
    def extract_verification_info(page_texts: List[str]) -> Dict[str, Any]:
        """
        Deep TrackÏóêÏÑú browser-use/PlaywrightÍ∞Ä ÏàòÏßëÌïú ÌÖçÏä§Ìä∏Îì§ÏùÑ Í∏∞Î∞òÏúºÎ°ú
        ÏûêÍ≤© Ï°∞Í±¥/Ï¶ùÎπô ÌÖçÏä§Ìä∏Î•º Íµ¨Ï°∞Ìôî.
        """
        if not settings.google_api_key:
            return {
                "criteria": {
                    "age": "Ï†ïÎ≥¥ ÏóÜÏùå",
                    "region": "Ï†ïÎ≥¥ ÏóÜÏùå",
                    "employment": "Ï†ïÎ≥¥ ÏóÜÏùå",
                    "others": [],
                },
                "evidence_text": "LLM ÎπÑÌôúÏÑ±Ìôî ÏÉÅÌÉú (ÎçîÎØ∏ Îç∞Ïù¥ÌÑ∞)",
            }

        prompt = LLMService.build_deep_track_prompt(page_texts)
        model = genai.GenerativeModel("gemini-1.5-flash")
        response = model.generate_content(prompt)
        raw = response.text or ""

        import json

        try:
            parsed = json.loads(raw)
        except Exception:
            parsed = {
                "criteria": {
                    "age": "ÌååÏã± Ïã§Ìå®",
                    "region": "ÌååÏã± Ïã§Ìå®",
                    "employment": "ÌååÏã± Ïã§Ìå®",
                    "others": [],
                },
                "evidence_text": "LLM ÏùëÎãµ ÌååÏã± Ïã§Ìå®",
            }
        return parsed

    # ===== Deep Track(BÏïà): facts + ÏÇ¨Ïö©ÏûêÏ†ïÎ≥¥ + DB Ï†ïÏ±ÖÏ†ïÎ≥¥ ‚Üí ÏµúÏ¢Ö ÏïàÎÇ¥ÏÑú(JSON) =====
    @staticmethod
    def make_user_guide(
        age: Optional[int],
        region: Optional[str],
        policy: Policy,
        deep_facts: Dict[str, Any],
        evidence_text: Optional[str] = None,
    ) -> Dict[str, Any]:
        """
        Deep Track Í≤∞Í≥º(facts) + ÏÇ¨Ïö©Ïûê Ï†ïÎ≥¥ + Ï†ïÏ±Ö(DB)ÏùÑ Ìï©Ï≥ê
        'Ïã†Ï≤≠ Í∞ÄÎä• Ïó¨Î∂Ä / ÌïÑÏöî ÏÑúÎ•ò / Ïã†Ï≤≠ Ï†àÏ∞®'Î•º Íµ¨Ï°∞ÌôîÎêú JSONÏúºÎ°ú ÏÉùÏÑ±ÌïúÎã§.
        (BÏïà: Î∞±ÏóîÎìúÏóêÏÑú ÏôÑÏÑ±Ìòï ÏïàÎÇ¥ÏÑú ÏÉùÏÑ±)
        """
        # 1) LLM ÎπÑÌôúÏÑ±ÌôîÎ©¥: facts Í∏∞Î∞òÏúºÎ°ú ÏµúÏÜå ÏïàÎÇ¥ÏÑú ÏÉùÏÑ± (ÌåêÎã®ÏùÄ WARNING)
        if not settings.google_api_key:
            return {
                "badge_status": BadgeStatus.WARNING.value,
                "can_apply": False,
                "summary": f"'{policy.title}' ÏïàÎÇ¥Î•º ÏÉùÏÑ±ÌñàÏäµÎãàÎã§. (LLM ÎπÑÌôúÏÑ±ÌôîÎ°ú ÏûêÎèô ÌåêÎã®ÏùÄ Î≥¥Î•ò)",
                "required_documents": (deep_facts or {}).get("required_documents") or [],
                "apply_steps": (deep_facts or {}).get("apply_steps") or [],
                "apply_channel": (deep_facts or {}).get("apply_channel"),
                "apply_period": (deep_facts or {}).get("apply_period"),
                "contact": (deep_facts or {}).get("contact") or {},
                "missing_info": ["LLM ÎπÑÌôúÏÑ±Ìôî ÏÉÅÌÉúÎ°ú Ïã†Ï≤≠ Í∞ÄÎä• Ïó¨Î∂Ä ÏûêÎèô ÌåêÎã® Î∂àÍ∞Ä"],
                "evidence_text": evidence_text,
            }

        user_age = f"{age}ÏÑ∏" if age is not None else "ÎÇòÏù¥ Ï†ïÎ≥¥ ÏóÜÏùå"
        user_region = region or "ÏßÄÏó≠ Ï†ïÎ≥¥ ÏóÜÏùå"

        facts_json = json.dumps(deep_facts or {}, ensure_ascii=False)

        prompt = f"""
ÎÑàÎäî ÎåÄÌïúÎØºÍµ≠ Ï≤≠ÎÖÑÏ†ïÏ±Ö Ïã†Ï≤≠ ÏïàÎÇ¥Î•º ÎßåÎìúÎäî Ï†ÑÎ¨∏Í∞ÄÏïº.

ÏïÑÎûò ÏÇ¨Ïö©Ïûê Ï†ïÎ≥¥ + Ï†ïÏ±Ö DB Ï†ïÎ≥¥ + Deep TrackÏúºÎ°ú Ï∂îÏ∂úÌïú ÏµúÏã† ÏõêÎ¨∏ factsÎ•º Ï¢ÖÌï©Ìï¥ÏÑú,
ÏÇ¨Ïö©ÏûêÏóêÍ≤å Î≥¥Ïó¨Ï§Ñ "ÏµúÏ¢Ö ÏïàÎÇ¥ÏÑú"Î•º JSONÏúºÎ°ú ÎßåÎì§Ïñ¥Îùº.

ÏöîÍµ¨ÏÇ¨Ìï≠:
- eligibility ÌåêÎã®ÏùÄ deep_facts.criteriaÎ•º Í∑ºÍ±∞Î°ú ÌïòÎêò, Ï†ïÎ≥¥Í∞Ä Î∂ÄÏ°±ÌïòÎ©¥ WARNING Ï≤òÎ¶¨ÌïòÍ≥† missing_infoÏóê Î¨¥ÏóáÏù¥ Î∂ÄÏ°±ÌïúÏßÄ Ï†ÅÏñ¥Îùº.
- required_documents/apply_steps/contact Îì±ÏùÄ deep_factsÎ•º ÏµúÎåÄÌïú Í∑∏ÎåÄÎ°ú ÌôúÏö©ÌïòÎêò, ÌëúÌòÑÏùÄ ÏÇ¨Ïö©Ïûê ÏπúÌôîÏ†ÅÏúºÎ°ú Îã§Îì¨Ïñ¥Îùº.
- Î∞òÎìúÏãú JSONÎßå Ï∂úÎ†•. Ï∂îÍ∞Ä Î¨∏Ïû• Í∏àÏßÄ.

Ï∂úÎ†• JSON Ïä§ÌÇ§Îßà:
{{
  "badge_status": "PASS" | "WARNING" | "FAIL",
  "can_apply": true|false,
  "summary": "ÏÇ¨Ïö©ÏûêÏóêÍ≤å Î≥¥Ïó¨Ï§Ñ Ìïú Îã®ÎùΩ ÏöîÏïΩ",
  "required_documents": ["...", "..."],
  "apply_steps": [{{"step": 1, "title": "...", "detail": "...", "url": "..."}}],
  "apply_channel": "Ïò®ÎùºÏù∏/Î∞©Î¨∏/Ïö∞Ìé∏/ÌòºÌï©" | null,
  "apply_period": "..." | null,
  "contact": {{"org":"...", "tel":"...", "site":"..."}},
  "missing_info": ["ÌåêÎã®Ïóê ÌïÑÏöîÌïú Ï∂îÍ∞Ä Ï†ïÎ≥¥...", "..."],
  "evidence_text": "ÌïµÏã¨ Í∑ºÍ±∞ Î∞úÏ∑å"
}}

ÏÇ¨Ïö©Ïûê Ï†ïÎ≥¥:
- ÎÇòÏù¥: {user_age}
- ÏßÄÏó≠: {user_region}

Ï†ïÏ±Ö(DB) Î©îÌÉÄ:
- title: {policy.title}
- category: {policy.category}
- region(meta): {policy.region}
- age_min~age_max(meta): {policy.age_min}~{policy.age_max}
- apply_period_raw(meta): {policy.apply_period_raw}
- apply_url(meta): {policy.apply_url}
- target_url(meta): {policy.target_url}

Deep facts(JSON):
{facts_json}

ÏõêÎ¨∏ Í∑ºÍ±∞(evidence_text):
{evidence_text or ""}
        """.strip()

        try:
            model = genai.GenerativeModel("gemini-2.5-flash-lite")
            response = model.generate_content(prompt)
            raw = (response.text or "").strip()
            parsed = LLMService._parse_fast_track_result(raw)
        except Exception as e:
            logger.error("[LLMService] make_user_guide Ïã§Ìå® (%s: %s)", e.__class__.__name__, str(e))
            return {
                "badge_status": BadgeStatus.WARNING.value,
                "can_apply": False,
                "summary": "ÏïàÎÇ¥ÏÑú ÏÉùÏÑ± Ï§ë Ïò§Î•òÍ∞Ä Î∞úÏÉùÌñàÏäµÎãàÎã§.",
                "required_documents": (deep_facts or {}).get("required_documents") or [],
                "apply_steps": (deep_facts or {}).get("apply_steps") or [],
                "apply_channel": (deep_facts or {}).get("apply_channel"),
                "apply_period": (deep_facts or {}).get("apply_period"),
                "contact": (deep_facts or {}).get("contact") or {},
                "missing_info": [f"LLM Ìò∏Ï∂ú Ïã§Ìå®: {e.__class__.__name__}"],
                "evidence_text": evidence_text,
            }

        # 2) ÏµúÏÜå ÌïÑÎìú Î≥¥Ï†ï + Enum Î¨∏ÏûêÏó¥ Ï†ïÍ∑úÌôî
        badge = (parsed.get("badge_status") or "WARNING").upper()
        if badge not in ("PASS", "WARNING", "FAIL"):
            badge = "WARNING"

        parsed["badge_status"] = badge
        parsed.setdefault("can_apply", False)
        parsed.setdefault("summary", "")
        parsed.setdefault("required_documents", [])
        parsed.setdefault("apply_steps", [])
        parsed.setdefault("apply_channel", None)
        parsed.setdefault("apply_period", None)
        parsed.setdefault("contact", {})
        parsed.setdefault("missing_info", [])
        parsed.setdefault("evidence_text", evidence_text)

        return parsed
    
    # =========================
    # ‚úÖ Scholarships (BÏïà): Ïπ¥ÎìúÌòï ÏöîÏïΩ + Ï∫êÏãú
    # =========================
    SCHOLARSHIP_PROMPT_VERSION = 1

    @staticmethod
    def _build_scholarship_card_prompt(
        scholarship: Scholarship,
    ) -> str:
        """
        Ïû•ÌïôÍ∏à ÏõêÎ¨∏(ÏÑ†Î∞ú/Ïú†ÏßÄ/ÏßÄÍ∏âÏï°)ÏùÑ Ïπ¥ÎìúÌòïÏúºÎ°ú 'Ï†ïÎ¶¨'ÌïòÎäî ÌîÑÎ°¨ÌîÑÌä∏.
        - ÏÇ¨Ïö©Ïûê ÎßûÏ∂§ Ï∂îÏ≤ú(Ïä§ÏΩîÏñ¥ÎßÅ)ÏùÄ ÎùºÏö∞ÌÑ∞/ÏÑúÎπÑÏä§ÏóêÏÑú Îî∞Î°ú Ìï¥ÎèÑ ÎêòÍ≥†
        Ïó¨Í∏∞ÏÑúÎäî ÏùºÎã® "Ï†ïÎ¶¨"Ïóê ÏßëÏ§ë(Ï∫êÏãú Ïû¨ÏÇ¨Ïö© Í∑πÎåÄÌôî).
        """
        selection = (scholarship.selection_criteria or "").strip()
        retention = (scholarship.retention_condition or "").strip()
        benefit = (scholarship.benefit or "").strip()
        notes = (scholarship.notes or "").strip()

        # ÎÑàÎ¨¥ Í∏∏Î©¥ ÏûêÎ•¥Í∏∞(LLM ÎπÑÏö©/Ïã§Ìå® Î∞©ÏßÄ)
        def _clip(s: str, n: int = 6000) -> str:
            if len(s) <= n:
                return s
            return s[:n]

        selection = _clip(selection, 5000)
        retention = _clip(retention, 4000)
        benefit = _clip(benefit, 2000)
        notes = _clip(notes, 1500)

        prompt = f"""
ÎÑàÎäî ÎåÄÌïôÍµê Ïû•ÌïôÍ∏à ÏïàÎÇ¥ ÌéòÏù¥ÏßÄÎ•º "Ïπ¥Îìú UI"Ïö©ÏúºÎ°ú ÏöîÏïΩ/Ï†ïÎ¶¨ÌïòÎäî Ï†ÑÎ¨∏Í∞ÄÎã§.

ÏïÑÎûò Ïû•ÌïôÍ∏à ÏõêÎ¨∏ÏùÑ ÏùΩÍ≥†, ÏÇ¨Ïö©ÏûêÍ∞Ä ÌïúÎààÏóê Ïù¥Ìï¥Ìï† Ïàò ÏûàÎèÑÎ°ù "Ïπ¥ÎìúÌòï JSON"Îßå Ï∂úÎ†•Ìï¥Îùº.
‚ö†Ô∏è Í∑úÏπô:
- Î∞òÎìúÏãú JSONÎßå Ï∂úÎ†•(Ï∂îÍ∞Ä Î¨∏Ïû•/ÏÑ§Î™Ö Í∏àÏßÄ)
- Î™®Î•¥Î©¥ Ï∂îÏ∏°ÌïòÏßÄ ÎßêÍ≥† null/Îπà Î∞∞Ïó¥Î°ú Îë¨Îùº
- eligibility_bullets/retention_bullets/notes_bulletsÎäî Í∞Å 3~6Í∞ú Ïù¥ÎÇ¥, ÏßßÏùÄ Î¨∏Ïû•ÏúºÎ°ú
- gpa_minÏùÄ ÏõêÎ¨∏Ïóê Î™ÖÏãúÎêú ÏµúÏÜåÌèâÏ†êÏù¥ ÏûàÏùÑ ÎïåÎßå Ïà´Ïûê(Ïòà: 3.5)Î°ú Ï∂îÏ∂ú

Ï∂úÎ†• Ïä§ÌÇ§Îßà(JSON):
{{
    "one_liner": "Ïû•ÌïôÍ∏à ÌïµÏã¨ Ìïú Ï§Ñ ÏöîÏïΩ",
    "benefit_summary": "ÏßÄÍ∏â/Í∞êÎ©¥ ÏöîÏïΩ(ÏßßÍ≤å)" | null,
    "eligibility_bullets": ["ÏÑ†Î∞ú/ÏßÄÏõê ÎåÄÏÉÅ ÌïµÏã¨", "..."],
    "retention_bullets": ["Ïú†ÏßÄ Ï°∞Í±¥ ÌïµÏã¨", "..."],
    "notes_bullets": ["ÏòàÏô∏/Ï£ºÏùò/ÏÇ∞Ï†ï Í∏∞Ï§Ä", "..."],
    "gpa_min": 3.5 | null,
    "keywords": ["ÌÇ§ÏõåÎìú1","ÌÇ§ÏõåÎìú2","ÌÇ§ÏõåÎìú3"]
}}

[Ïû•ÌïôÍ∏à Î©îÌÉÄ]
- name: {scholarship.name}
- category: {scholarship.category}
- source_url: {scholarship.source_url}

[ÏÑ†Î∞úÍ∏∞Ï§Ä ÏõêÎ¨∏]
{selection}

[Ïú†ÏßÄÏ°∞Í±¥ ÏõêÎ¨∏]
{retention}

[ÏßÄÍ∏âÏï°/ÌòúÌÉù ÏõêÎ¨∏]
{benefit}

[Í∏∞ÌÉÄ Î©îÎ™®]
{notes}
        """.strip()
        return prompt

    @staticmethod
    def _parse_scholarship_card(raw: str) -> Dict[str, Any]:
        """
        Í∏∞Ï°¥ _parse_fast_track_resultÎäî policyÏö© ÌÇ§Í∞Ä ÏÑûÏùº Ïàò ÏûàÏñ¥ÏÑú,
        scholarship cardÎäî Î≥ÑÎèÑ ÌååÏÑúÎ°ú 'ÏµúÏÜå ÌïÑÎìú Î≥¥Ï†ï'ÍπåÏßÄ ÏàòÌñâ.
        """
        parsed = LLMService._parse_fast_track_result(raw)

        # ÏµúÏÜå ÌïÑÎìú Î≥¥Ï†ï
        out: Dict[str, Any] = {}
        out["one_liner"] = (parsed.get("one_liner") or "").strip() or "Ïû•ÌïôÍ∏à ÏöîÏïΩ"
        out["benefit_summary"] = (parsed.get("benefit_summary") or None)

        def _as_list(v):
            if v is None:
                return []
            if isinstance(v, list):
                return [str(x).strip() for x in v if str(x).strip()]
            return [str(v).strip()] if str(v).strip() else []

        out["eligibility_bullets"] = _as_list(parsed.get("eligibility_bullets"))
        out["retention_bullets"] = _as_list(parsed.get("retention_bullets"))
        out["notes_bullets"] = _as_list(parsed.get("notes_bullets"))
        out["keywords"] = _as_list(parsed.get("keywords"))[:8]

        # gpa_min Ï†ïÍ∑úÌôî
        gpa_min = parsed.get("gpa_min")
        try:
            out["gpa_min"] = float(gpa_min) if gpa_min is not None else None
        except Exception:
            out["gpa_min"] = None

        return out

    @staticmethod
    def get_or_make_scholarship_card(
        db: Session,
        scholarship: Scholarship,
        prompt_version: Optional[int] = None,
        force: bool = False,
    ) -> Dict[str, Any]:
        """
        scholarship_id  prompt_version Ï∫êÏãú Ïö∞ÏÑ†.
        ÏóÜÏúºÎ©¥ LLM Ìò∏Ï∂ú ‚Üí DB Ï†ÄÏû• ‚Üí Î∞òÌôò.
        """
        pv = prompt_version or LLMService.SCHOLARSHIP_PROMPT_VERSION

        cache = (
            db.query(ScholarshipLLMCache)
            .filter(
                ScholarshipLLMCache.scholarship_id == scholarship.id,
                ScholarshipLLMCache.prompt_version == pv,
            )
            .first()
        )

        if cache and not force:
            return cache.card_json

        # LLM ÎπÑÌôúÏÑ±ÌôîÎ©¥: Í∞ÑÎã® fallback(Ï∫êÏãú Ï†ÄÏû•ÏùÄ ÏÑ†ÌÉù)
        if not settings.google_api_key:
            fallback = {
                "one_liner": f"{scholarship.name} Ïû•ÌïôÍ∏à",
                "benefit_summary": (scholarship.benefit or None),
                "eligibility_bullets": [],
                "retention_bullets": [],
                "notes_bullets": [],
                "gpa_min": None,
                "keywords": [],
            }
            if not cache:
                cache = ScholarshipLLMCache(
                    scholarship_id=scholarship.id,
                    prompt_version=pv,
                    card_json=fallback,
                )
                db.add(cache)
                db.commit()
                db.refresh(cache)
            else:
                cache.card_json = fallback
                db.add(cache)
                db.commit()
            return fallback

        prompt = LLMService._build_scholarship_card_prompt(scholarship)

        try:
            logger.info("[LLMService] Scholarship card Ìò∏Ï∂ú (scholarship_id=%s)", scholarship.id)
            model = genai.GenerativeModel("gemini-2.5-flash-lite")
            response = model.generate_content(prompt)
            raw_text = (response.text or "").strip()
            card = LLMService._parse_scholarship_card(raw_text)
        except Exception as e:
            logger.error(
                "[LLMService] Scholarship card Ïã§Ìå® (%s: %s)",
                e.__class__.__name__,
                str(e),
            )
            card = {
                "one_liner": f"{scholarship.name} Ïû•ÌïôÍ∏à",
                "benefit_summary": (scholarship.benefit or None),
                "eligibility_bullets": [],
                "retention_bullets": [],
                "notes_bullets": [f"LLM Ìò∏Ï∂ú Ïã§Ìå®: {e.__class__.__name__}"],
                "gpa_min": None,
                "keywords": [],
            }

        # upsert cache
        if not cache:
            cache = ScholarshipLLMCache(
                scholarship_id=scholarship.id,
                prompt_version=pv,
                card_json=card,
            )
        else:
            cache.card_json = card

        db.add(cache)
        db.commit()
        db.refresh(cache)
        return card