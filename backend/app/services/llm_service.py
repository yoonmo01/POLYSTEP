#app/services/llm_service.py
from typing import Any, Dict, List, Optional
import logging

import google.generativeai as genai
import json

from app.config import settings
from app.schemas import BadgeStatus, PolicySearchRequest
from app.models import Policy

logger = logging.getLogger(__name__)

if settings.google_api_key:
    genai.configure(api_key=settings.google_api_key)


class LLMService:
    @staticmethod
    def _fallback_summary(
        req: PolicySearchRequest,
        policy: Policy,
    ) -> Dict[str, Any]:
        """
        GOOGLE_API_KEY ë¯¸ì„¤ì • / LLM ì˜¤ë¥˜ ì‹œ ì‚¬ìš©í•˜ëŠ” ê·œì¹™ ê¸°ë°˜ ìš”ì•½.
        - region / category / age ë²”ìœ„ë¥¼ ì¡°í•©í•´ì„œ í•œ ì¤„ ìš”ì•½ ë¬¸ì¥ì„ ë§Œë“ ë‹¤.
        - ë±ƒì§€ëŠ” ì¼ë‹¨ WARNINGìœ¼ë¡œ ê³ ì • (ë‚˜ì¤‘ì— ë£°ì„ ë°”ê¿”ë„ ë¨).
        """
        parts: list[str] = []

        # ì§€ì—­
        if policy.region:
            parts.append(policy.region)

        # ëŒ€ë¶„ë¥˜(ì·¨ì—…Â·ì¼ìë¦¬ / ì†Œë“Â·ìƒí™œ ë“±)
        if policy.category:
            parts.append(policy.category)

        # ë‚˜ì´ ë²”ìœ„
        age_str = None
        if policy.age_min is not None and policy.age_max is not None:
            age_str = f"{policy.age_min}~{policy.age_max}ì„¸"
        elif policy.age_min is not None:
            age_str = f"{policy.age_min}ì„¸ ì´ìƒ"
        elif policy.age_max is not None:
            age_str = f"{policy.age_max}ì„¸ ì´í•˜"

        if age_str:
            parts.append(age_str)

        meta = " Â· ".join(parts) if parts else "ì²­ë…„ ì •ì±…"

        short_summary = f"{meta} ëŒ€ìƒì˜ '{policy.title}' ì§€ì›ì‚¬ì—…ì…ë‹ˆë‹¤."

        return {
            "badge_status": BadgeStatus.WARNING.value,
            "short_summary": short_summary,
            "reason": "LLM ë¹„í™œì„±í™” ìƒíƒœ ë˜ëŠ” í˜¸ì¶œ ì‹¤íŒ¨ (ë£° ê¸°ë°˜ ìš”ì•½)",
            "missing_criteria": [],
        }
    @staticmethod
    def _postprocess_badge(
        parsed: Dict[str, Any],
        policy: Policy,
        req: PolicySearchRequest,
    ) -> Dict[str, Any]:
        """
        Geminiê°€ ì¤€ badge_statusë¥¼ ê·¸ëŒ€ë¡œ ì“°ì§€ ì•Šê³ ,
        ì‚¬ëŒì´ ë³´ê¸° ë” ìì—°ìŠ¤ëŸ½ê²Œ í•œ ë²ˆ ë³´ì •í•˜ëŠ” ë‹¨ê³„.

        - FAILì¸ë° 'ì •ë³´ ë¶€ì¡± / íŒë‹¨ ë¶ˆê°€' ê³„ì—´ì´ë©´ WARNINGìœ¼ë¡œ ì™„í™”
        - ê°•í•œ ë¶€ì • ë¬¸êµ¬ê°€ ì „í˜€ ì—†ëŠ”ë° FAILì´ë©´ WARNINGìœ¼ë¡œ ì™„í™”
        """
        badge = (parsed.get("badge_status") or "").upper()
        reason = (parsed.get("reason") or "").strip()
        summary = (parsed.get("short_summary") or "").strip()

        # ğŸ” 1) ì •ë³´ ë¶€ì¡± / íŒë‹¨ ë¶ˆê°€ íŒ¨í„´ë“¤
        info_lack_keywords = [
            "íŒë‹¨í•  ìˆ˜ ì—†",
            "íŒë‹¨í•˜ê¸° ì–´ë µ",
            "íŒë‹¨í•  ìˆ˜ ì—†ì–´",
            "ì •ë³´ê°€ ì—†ì–´",
            "ì •ë³´ê°€ ë¶€ì¡±",
            "ë¶€ì¡±í•˜ì—¬",
            "ì¶”ê°€ ì •ë³´",
        ]

        # ğŸ” 2) ì§„ì§œ 'ì™„ì „ íƒˆë½' ëŠë‚Œì˜ ê°•í•œ ë¶€ì • íŒ¨í„´ë“¤
        strong_fail_keywords = [
            "ì‹ ì²­í•  ìˆ˜ ì—†",
            "ì‹ ì²­í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤",
            "ëŒ€ìƒì´ ì•„ë‹™ë‹ˆë‹¤",
            "ì§€ì› ëŒ€ìƒì´ ì•„ë‹™ë‹ˆë‹¤",
            "í•´ë‹¹ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤",
            "ì œì™¸ë©ë‹ˆë‹¤",
        ]

        # â¶ FAILì¸ ê²½ìš° â†’ ì •ë³´ ë¶€ì¡±ì´ë©´ WARNINGìœ¼ë¡œ ì™„í™”
        if badge == "FAIL":
            # (1) ì •ë³´ ë¶€ì¡± ê³„ì—´ì´ë©´ â†’ WARNINGìœ¼ë¡œ ì™„í™”
            if any(k in reason for k in info_lack_keywords):
                parsed["badge_status"] = BadgeStatus.WARNING.value
                return parsed

            # (2) ê°•í•œ ë¶€ì • ë¬¸êµ¬ê°€ í•˜ë‚˜ë„ ì—†ìœ¼ë©´ â†’ WARNINGìœ¼ë¡œ ì™„í™”
            if not any(k in reason for k in strong_fail_keywords):
                parsed["badge_status"] = BadgeStatus.WARNING.value
                return parsed

        # â· WARNINGì¸ë°, ë¬¸êµ¬ê°€ ë„ˆë¬´ ê°•í•˜ê²Œ "ì™„ì „ íƒˆë½"ì´ë©´ â†’ FAILë¡œ ê²©ìƒ
        if badge == "WARNING":
            text_for_check = reason + " " + summary
            if any(k in text_for_check for k in strong_fail_keywords):
                parsed["badge_status"] = BadgeStatus.FAIL.value
                return parsed
        # ë‚˜ë¨¸ì§€ëŠ” ê·¸ëŒ€ë¡œ ë°˜í™˜
        return parsed
    @staticmethod
    def _build_fast_track_prompt(
        req: PolicySearchRequest,
        policy: Policy,
    ) -> str:
        age_part = f"{req.age}ì„¸" if req.age is not None else "ë‚˜ì´ ì •ë³´ ì—†ìŒ"
        region_part = req.region or "ì§€ì—­ ì •ë³´ ì—†ìŒ"

        # ì •ì±… ì›ë¬¸ í…ìŠ¤íŠ¸ êµ¬ì„±:
        # 1ìˆœìœ„: policy.raw_text
        # 2ìˆœìœ„: raw_snippet + raw_expln + raw_support ì¡°í•©
        text_source = policy.raw_text

        if not text_source:
            pieces: list[str] = []
            for attr in ("raw_snippet", "raw_expln", "raw_support"):
                v = getattr(policy, attr, None)
                if v:
                    pieces.append(str(v))
            text_source = " ".join(pieces)

        text = text_source or ""
        if len(text) > 6000:
            text = text[:6000]

        prompt = (
            "ë‹¤ìŒì€ ëŒ€í•œë¯¼êµ­ ì²­ë…„ ì§€ì› ì •ì±…ì˜ ì›ë¬¸ ì¼ë¶€ì´ë‹¤.\n"
            "ì£¼ì–´ì§„ ì‚¬ìš©ìì˜ ë‚˜ì´ì™€ ì§€ì—­ ì •ë³´ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì´ ì •ì±…ì˜ ì‹ ì²­ ê°€ëŠ¥ì„±ì„ í‰ê°€í•˜ë¼.\n\n"
            "âš ï¸ íŒë‹¨ ì›ì¹™(ë§¤ìš° ì¤‘ìš”):\n"
            "1. ì •ì±… ì›ë¬¸ ë˜ëŠ” ë©”íƒ€ ì •ë³´ì— **ëª…ì‹œì ìœ¼ë¡œ ëŒ€ìƒì´ ì•„ë‹˜**ì´ ë“œëŸ¬ë‚˜ì§€ ì•ŠëŠ” í•œ FAILë¡œ íŒë‹¨í•˜ì§€ ë§ ê²ƒ.\n"
            "2. ì •ë³´ê°€ ë¶€ì¡±í•˜ê±°ë‚˜ ì¡°ê±´ì´ ì• ë§¤í•œ ê²½ìš°ì—ëŠ” ë°˜ë“œì‹œ WARNINGìœ¼ë¡œ íŒë‹¨í•  ê²ƒ.\n"
            "3. ì •ì±… ì›ë¬¸ì— ìê²© ìš”ê±´ì´ ì—†ì„ ê²½ìš°, ì•„ë˜ ì œê³µëœ ì •ì±… ë©”íƒ€ ì •ë³´(age/region)ë¥¼ ê·¼ê±°ë¡œ ê°€ëŠ¥ì„±ì„ ì¶”ì •í•  ê²ƒ.\n"
            "4. FAILì€ ë‹¤ìŒê³¼ ê°™ì€ ê²½ìš°ì—ë§Œ ì‚¬ìš©í•œë‹¤:\n"
            "   - ì—°ë ¹ ì´ˆê³¼/ë¯¸ë‹¬ì´ ëª…í™•í•¨\n"
            "   - ê±°ì£¼ ì§€ì—­ì´ ëª…í™•íˆ ë¶ˆì¼ì¹˜í•¨\n"
            "   - ì •ì±… ì›ë¬¸ì— 'ì§€ì› ëŒ€ìƒì´ ì•„ë‹˜', 'ì‹ ì²­ ë¶ˆê°€'ê°€ ëª…ì‹œë¨\n\n"
            "ì‘ë‹µ í˜•ì‹ì€ ë°˜ë“œì‹œ JSON í•œ ì¤„ë¡œë§Œ ì¶œë ¥í•œë‹¤.\n"
            '{\n'
            '  "badge_status": "PASS" | "WARNING" | "FAIL",\n'
            '  "short_summary": "ì‚¬ìš©ì ê´€ì ì˜ í•œ ë¬¸ì¥ ìš”ì•½",\n'
            '  "reason": "íŒë‹¨ ê·¼ê±°ë¥¼ ê°„ë‹¨íˆ ì„¤ëª…",\n'
            '  "missing_criteria": ["ë¶€ì¡±í•œ ì¡°ê±´ì´ ìˆë‹¤ë©´ ë‚˜ì—´"]\n'
            "}\n\n"
            f"[ì‚¬ìš©ì ì •ë³´]\n"
            f"- ë‚˜ì´: {age_part}\n"
            f"- ì§€ì—­: {region_part}\n\n"
            f"[ì •ì±… ë©”íƒ€ ì •ë³´]\n"
            f"- ì •ì±… ì§€ì—­(meta): {policy.region}\n"
            f"- ì—°ë ¹ ë²”ìœ„(meta): {policy.age_min} ~ {policy.age_max}\n"
            f"- ì •ì±… ë¶„ì•¼(meta): {policy.category}\n\n"
            f"[ì •ì±… ì œëª©]\n"
            f"{policy.title}\n\n"
            f"[ì •ì±… ì›ë¬¸ ì¼ë¶€]\n"
            f"{text}\n"
        )
        return prompt

    @staticmethod
    def _parse_fast_track_result(raw: str) -> Dict[str, Any]:
        import json
        # 0) ì›ë³¸ ë¬¸ìì—´ ì •ë¦¬
        s = raw.strip()

        # 1) ```json ... ``` ê°™ì€ ë§ˆí¬ë‹¤ìš´ ì½”ë“œë¸”ë¡ì´ë©´ ë²—ê²¨ë‚´ê¸°
        if s.startswith("```"):
            # ì²« ì¤„(ì˜ˆ: ```json) ì œê±°
            first_newline = s.find("\n")
            if first_newline != -1:
                s = s[first_newline + 1 :]
            # ë§ˆì§€ë§‰ì˜ ``` ì œê±°
            if s.endswith("```"):
                s = s[:-3]
            s = s.strip()

        # 2) í˜¹ì‹œ ì•ë’¤ì— ë‹¤ë¥¸ í…ìŠ¤íŠ¸ê°€ ì„ì—¬ ìˆì–´ë„,
        #    ê°€ì¥ ë°”ê¹¥ ìª½ì˜ { ... } ë²”ìœ„ë§Œ ì˜ë¼ë‚´ê¸°
        if "{" in s and "}" in s:
            start = s.find("{")
            end = s.rfind("}")
            if start != -1 and end != -1 and end > start:
                s = s[start : end + 1]

        try:
            return json.loads(s)
        except Exception as e:
            # ğŸ”¥ ì—¬ê¸°ì„œ LLMì´ ë³´ë‚¸(ì •ë¦¬ëœ) ì›ë¬¸ ì¼ë¶€ë¥¼ ë¡œê·¸ë¡œ ì°ì–´ë³´ì
            logger.warning(
                "[LLMService] FastTrack JSON íŒŒì‹± ì‹¤íŒ¨ (%s): raw=%r",
                e.__class__.__name__,
                s[:300],  # ë„ˆë¬´ ê¸¸ë©´ ì˜ë¼ì„œ
            )
            return {
                "badge_status": "WARNING",
                "short_summary": "ì •ì±… ìš”ì•½ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.",
                "reason": "LLM ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨",
                "missing_criteria": [],
            }

    @staticmethod
    def evaluate_eligibility(
        req: PolicySearchRequest,
        policy: Policy,
    ) -> Dict[str, Any]:
        """
        Fast Trackì—ì„œ ê° ì •ì±…ë³„ë¡œ PASS/WARNING/FAIL ë±ƒì§€ì™€ ìš”ì•½ì„ ë§Œë“œëŠ” í•¨ìˆ˜.
        - GOOGLE_API_KEY ì—†ìœ¼ë©´: ë°”ë¡œ ë”ë¯¸ ê²°ê³¼
        - LLM í˜¸ì¶œ ì¤‘ ì—ëŸ¬ ë‚˜ë©´: ë”ë¯¸ ê²°ê³¼ + ì—ëŸ¬ ì •ë³´ ì‚´ì§ í¬í•¨
        """
        # 1) í‚¤ê°€ ì•„ì˜ˆ ì—†ìœ¼ë©´: ê·œì¹™ ê¸°ë°˜ ê°„ë‹¨ ìš”ì•½
        if not settings.google_api_key:
            logger.warning("[LLMService] GOOGLE_API_KEY ë¯¸ì„¤ì • â†’ fallback ì‚¬ìš©")
            return LLMService._fallback_summary(req, policy)

        prompt = LLMService._build_fast_track_prompt(req, policy)

        try:
            # ğŸ” ì—¬ê¸° ëª¨ë¸ ì´ë¦„ì€ í™˜ê²½ì— ë§ê²Œ ë‚˜ì¤‘ì— ì¡°ì • ê°€ëŠ¥
            logger.info("[LLMService] Gemini FastTrack í˜¸ì¶œ ì‹œì‘ (policy_id=%s)", policy.id)
            model = genai.GenerativeModel("gemini-2.5-flash-lite")
            response = model.generate_content(prompt)
            raw_text = response.text or ""
            logger.debug("[LLMService] Gemini raw ì‘ë‹µ ì¼ë¶€: %r", raw_text[:200])

            parsed = LLMService._parse_fast_track_result(raw_text)
            # ğŸ”§ LLMì´ ì¤€ badgeë¥¼ ì‚¬ëŒì´ ë³´ê¸° ì¢‹ê²Œ í•œ ë²ˆ í›„ì²˜ë¦¬
            parsed = LLMService._postprocess_badge(parsed, policy, req)

            # ğŸ”¥ íŒŒì‹±ì€ ëëŠ”ë°, ì—¬ì „íˆ ìš°ë¦¬ê°€ ì •ì˜í•œ 'ì‹¤íŒ¨ ë©”ì‹œì§€'ë©´ â†’ fallbackìœ¼ë¡œ ëŒ€ì²´
            if parsed.get("short_summary") == "ì •ì±… ìš”ì•½ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.":
                logger.info(
                    "[LLMService] LLM íŒŒì‹± ê²°ê³¼ê°€ ì‹¤íŒ¨ ê¸°ë³¸ê°’ â†’ fallback ìš”ì•½ ì‚¬ìš© (policy_id=%s)",
                    policy.id,
                )
                return LLMService._fallback_summary(req, policy)

            return parsed

        except Exception as e:
            # LLM í˜¸ì¶œ ì‹¤íŒ¨í•´ë„ FastAPIëŠ” 500 ì•ˆ ë‚´ê³ , ê·œì¹™ ê¸°ë°˜ ìš”ì•½ ì‚¬ìš©
            logger.error(
                "[LLMService] Gemini í˜¸ì¶œ ì˜ˆì™¸ ë°œìƒ â†’ fallback ì‚¬ìš© (%s: %s)",
                e.__class__.__name__,
                str(e),
            )
            fallback = LLMService._fallback_summary(req, policy)
            fallback["reason"] = f"LLM í˜¸ì¶œ ì‹¤íŒ¨: {e.__class__.__name__}"
            return fallback

    # ===== Deep Trackì—ì„œ ì‚¬ìš©í•  ì¶”ì¶œìš© =====
    @staticmethod
    def build_deep_track_prompt(page_texts: List[str]) -> str:
        combined = "\n\n---\n\n".join(page_texts)
        if len(combined) > 12000:
            combined = combined[:12000]

        prompt = (
            "ë‹¤ìŒì€ íŠ¹ì • ì²­ë…„ ì •ì±… í˜ì´ì§€ì—ì„œ ìˆ˜ì§‘í•œ í…ìŠ¤íŠ¸ì´ë‹¤.\n"
            "ì´ í…ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‹ ì²­ ìê²©/ëŒ€ìƒ/ê¸°ê°„/í•„ìˆ˜ ì„œë¥˜ ë“± ì¤‘ìš”í•œ ì¡°ê±´ì„ êµ¬ì¡°í™”í•´ë¼.\n\n"
            "ì‘ë‹µ í˜•ì‹ì€ ë°˜ë“œì‹œ JSON í•œ ì¤„ë¡œë§Œ ì¶œë ¥í•œë‹¤.\n"
            "{\n"
            '  "criteria": {\n'
            '    "age": "ì˜ˆ: ë§Œ 19~34ì„¸",\n'
            '    "region": "ì˜ˆ: ì„œìš¸ ê±°ì£¼",\n'
            '    "employment": "ì˜ˆ: ë¯¸ì·¨ì—… ë˜ëŠ” í”„ë¦¬ëœì„œ",\n'
            '    "others": ["ê¸°íƒ€ ì¡°ê±´1", "ê¸°íƒ€ ì¡°ê±´2", ...]\n'
            "  },\n"
            '  "evidence_text": "ê°€ì¥ í•µì‹¬ì ì¸ ë¶€ë¶„ë§Œ ë°œì·Œí•œ ìš”ì•½ í…ìŠ¤íŠ¸"\n'
            "}\n\n"
            "ë‹¤ìŒì€ ìˆ˜ì§‘ëœ ì›ë¬¸ì´ë‹¤:\n"
            f"{combined}\n"
        )
        return prompt

    @staticmethod
    def extract_verification_info(page_texts: List[str]) -> Dict[str, Any]:
        """
        Deep Trackì—ì„œ browser-use/Playwrightê°€ ìˆ˜ì§‘í•œ í…ìŠ¤íŠ¸ë“¤ì„ ê¸°ë°˜ìœ¼ë¡œ
        ìê²© ì¡°ê±´/ì¦ë¹™ í…ìŠ¤íŠ¸ë¥¼ êµ¬ì¡°í™”.
        """
        if not settings.google_api_key:
            return {
                "criteria": {
                    "age": "ì •ë³´ ì—†ìŒ",
                    "region": "ì •ë³´ ì—†ìŒ",
                    "employment": "ì •ë³´ ì—†ìŒ",
                    "others": [],
                },
                "evidence_text": "LLM ë¹„í™œì„±í™” ìƒíƒœ (ë”ë¯¸ ë°ì´í„°)",
            }

        prompt = LLMService.build_deep_track_prompt(page_texts)
        model = genai.GenerativeModel("gemini-1.5-flash")
        response = model.generate_content(prompt)
        raw = response.text or ""

        import json

        try:
            parsed = json.loads(raw)
        except Exception:
            parsed = {
                "criteria": {
                    "age": "íŒŒì‹± ì‹¤íŒ¨",
                    "region": "íŒŒì‹± ì‹¤íŒ¨",
                    "employment": "íŒŒì‹± ì‹¤íŒ¨",
                    "others": [],
                },
                "evidence_text": "LLM ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨",
            }
        return parsed

    # ===== Deep Track(Bì•ˆ): facts + ì‚¬ìš©ìì •ë³´ + DB ì •ì±…ì •ë³´ â†’ ìµœì¢… ì•ˆë‚´ì„œ(JSON) =====
    @staticmethod
    def make_user_guide(
        age: Optional[int],
        region: Optional[str],
        policy: Policy,
        deep_facts: Dict[str, Any],
        evidence_text: Optional[str] = None,
    ) -> Dict[str, Any]:
        """
        Deep Track ê²°ê³¼(facts) + ì‚¬ìš©ì ì •ë³´ + ì •ì±…(DB)ì„ í•©ì³
        'ì‹ ì²­ ê°€ëŠ¥ ì—¬ë¶€ / í•„ìš” ì„œë¥˜ / ì‹ ì²­ ì ˆì°¨'ë¥¼ êµ¬ì¡°í™”ëœ JSONìœ¼ë¡œ ìƒì„±í•œë‹¤.
        (Bì•ˆ: ë°±ì—”ë“œì—ì„œ ì™„ì„±í˜• ì•ˆë‚´ì„œ ìƒì„±)
        """
        # 1) LLM ë¹„í™œì„±í™”ë©´: facts ê¸°ë°˜ìœ¼ë¡œ ìµœì†Œ ì•ˆë‚´ì„œ ìƒì„± (íŒë‹¨ì€ WARNING)
        if not settings.google_api_key:
            return {
                "badge_status": BadgeStatus.WARNING.value,
                "can_apply": False,
                "summary": f"'{policy.title}' ì•ˆë‚´ë¥¼ ìƒì„±í–ˆìŠµë‹ˆë‹¤. (LLM ë¹„í™œì„±í™”ë¡œ ìë™ íŒë‹¨ì€ ë³´ë¥˜)",
                "required_documents": (deep_facts or {}).get("required_documents") or [],
                "apply_steps": (deep_facts or {}).get("apply_steps") or [],
                "apply_channel": (deep_facts or {}).get("apply_channel"),
                "apply_period": (deep_facts or {}).get("apply_period"),
                "contact": (deep_facts or {}).get("contact") or {},
                "missing_info": ["LLM ë¹„í™œì„±í™” ìƒíƒœë¡œ ì‹ ì²­ ê°€ëŠ¥ ì—¬ë¶€ ìë™ íŒë‹¨ ë¶ˆê°€"],
                "evidence_text": evidence_text,
            }

        user_age = f"{age}ì„¸" if age is not None else "ë‚˜ì´ ì •ë³´ ì—†ìŒ"
        user_region = region or "ì§€ì—­ ì •ë³´ ì—†ìŒ"

        facts_json = json.dumps(deep_facts or {}, ensure_ascii=False)

        prompt = f"""
ë„ˆëŠ” ëŒ€í•œë¯¼êµ­ ì²­ë…„ì •ì±… ì‹ ì²­ ì•ˆë‚´ë¥¼ ë§Œë“œëŠ” ì „ë¬¸ê°€ì•¼.

ì•„ë˜ ì‚¬ìš©ì ì •ë³´ + ì •ì±… DB ì •ë³´ + Deep Trackìœ¼ë¡œ ì¶”ì¶œí•œ ìµœì‹  ì›ë¬¸ factsë¥¼ ì¢…í•©í•´ì„œ,
ì‚¬ìš©ìì—ê²Œ ë³´ì—¬ì¤„ "ìµœì¢… ì•ˆë‚´ì„œ"ë¥¼ JSONìœ¼ë¡œ ë§Œë“¤ì–´ë¼.

ìš”êµ¬ì‚¬í•­:
- eligibility íŒë‹¨ì€ deep_facts.criteriaë¥¼ ê·¼ê±°ë¡œ í•˜ë˜, ì •ë³´ê°€ ë¶€ì¡±í•˜ë©´ WARNING ì²˜ë¦¬í•˜ê³  missing_infoì— ë¬´ì—‡ì´ ë¶€ì¡±í•œì§€ ì ì–´ë¼.
- required_documents/apply_steps/contact ë“±ì€ deep_factsë¥¼ ìµœëŒ€í•œ ê·¸ëŒ€ë¡œ í™œìš©í•˜ë˜, í‘œí˜„ì€ ì‚¬ìš©ì ì¹œí™”ì ìœ¼ë¡œ ë‹¤ë“¬ì–´ë¼.
- ë°˜ë“œì‹œ JSONë§Œ ì¶œë ¥. ì¶”ê°€ ë¬¸ì¥ ê¸ˆì§€.

ì¶œë ¥ JSON ìŠ¤í‚¤ë§ˆ:
{{
  "badge_status": "PASS" | "WARNING" | "FAIL",
  "can_apply": true|false,
  "summary": "ì‚¬ìš©ìì—ê²Œ ë³´ì—¬ì¤„ í•œ ë‹¨ë½ ìš”ì•½",
  "required_documents": ["...", "..."],
  "apply_steps": [{{"step": 1, "title": "...", "detail": "...", "url": "..."}}],
  "apply_channel": "ì˜¨ë¼ì¸/ë°©ë¬¸/ìš°í¸/í˜¼í•©" | null,
  "apply_period": "..." | null,
  "contact": {{"org":"...", "tel":"...", "site":"..."}},
  "missing_info": ["íŒë‹¨ì— í•„ìš”í•œ ì¶”ê°€ ì •ë³´...", "..."],
  "evidence_text": "í•µì‹¬ ê·¼ê±° ë°œì·Œ"
}}

ì‚¬ìš©ì ì •ë³´:
- ë‚˜ì´: {user_age}
- ì§€ì—­: {user_region}

ì •ì±…(DB) ë©”íƒ€:
- title: {policy.title}
- category: {policy.category}
- region(meta): {policy.region}
- age_min~age_max(meta): {policy.age_min}~{policy.age_max}
- apply_period_raw(meta): {policy.apply_period_raw}
- apply_url(meta): {policy.apply_url}
- target_url(meta): {policy.target_url}

Deep facts(JSON):
{facts_json}

ì›ë¬¸ ê·¼ê±°(evidence_text):
{evidence_text or ""}
        """.strip()

        try:
            model = genai.GenerativeModel("gemini-2.5-flash-lite")
            response = model.generate_content(prompt)
            raw = (response.text or "").strip()
            parsed = LLMService._parse_fast_track_result(raw)
        except Exception as e:
            logger.error("[LLMService] make_user_guide ì‹¤íŒ¨ (%s: %s)", e.__class__.__name__, str(e))
            return {
                "badge_status": BadgeStatus.WARNING.value,
                "can_apply": False,
                "summary": "ì•ˆë‚´ì„œ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
                "required_documents": (deep_facts or {}).get("required_documents") or [],
                "apply_steps": (deep_facts or {}).get("apply_steps") or [],
                "apply_channel": (deep_facts or {}).get("apply_channel"),
                "apply_period": (deep_facts or {}).get("apply_period"),
                "contact": (deep_facts or {}).get("contact") or {},
                "missing_info": [f"LLM í˜¸ì¶œ ì‹¤íŒ¨: {e.__class__.__name__}"],
                "evidence_text": evidence_text,
            }

        # 2) ìµœì†Œ í•„ë“œ ë³´ì • + Enum ë¬¸ìì—´ ì •ê·œí™”
        badge = (parsed.get("badge_status") or "WARNING").upper()
        if badge not in ("PASS", "WARNING", "FAIL"):
            badge = "WARNING"

        parsed["badge_status"] = badge
        parsed.setdefault("can_apply", False)
        parsed.setdefault("summary", "")
        parsed.setdefault("required_documents", [])
        parsed.setdefault("apply_steps", [])
        parsed.setdefault("apply_channel", None)
        parsed.setdefault("apply_period", None)
        parsed.setdefault("contact", {})
        parsed.setdefault("missing_info", [])
        parsed.setdefault("evidence_text", evidence_text)

        return parsed