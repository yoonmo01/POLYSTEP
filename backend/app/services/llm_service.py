#app/services/llm_service.py
from typing import Any, Dict, List, Optional

import google.generativeai as genai

from app.config import settings
from app.schemas import BadgeStatus, PolicySearchRequest
from app.models import Policy

if settings.google_api_key:
    genai.configure(api_key=settings.google_api_key)


class LLMService:
    @staticmethod
    def _build_fast_track_prompt(
        req: PolicySearchRequest,
        policy: Policy,
    ) -> str:
        age_part = f"{req.age}ì„¸" if req.age is not None else "ë‚˜ì´ ì •ë³´ ì—†ìŒ"
        region_part = req.region or "ì§€ì—­ ì •ë³´ ì—†ìŒ"

        text = policy.raw_text or ""
        if len(text) > 6000:
            text = text[:6000]

        prompt = (
            "ë‹¤ìŒì€ ì²­ë…„ ì§€ì› ì •ì±…ì˜ ì›ë¬¸ ì¼ë¶€ì´ë‹¤.\n"
            "ì£¼ì–´ì§„ ì‚¬ìš©ìì˜ ë‚˜ì´/ì§€ì—­ì„ ê¸°ì¤€ìœ¼ë¡œ ì´ ì •ì±…ì˜ ì‹ ì²­ ê°€ëŠ¥ì„±ì„ í‰ê°€í•´ë¼.\n\n"
            "ì‘ë‹µ í˜•ì‹ì€ ë°˜ë“œì‹œ JSON í•œ ì¤„ë¡œë§Œ ì¶œë ¥í•œë‹¤.\n"
            '{\n'
            '  "badge_status": "PASS" | "WARNING" | "FAIL",\n'
            '  "short_summary": "í•œ ë¬¸ì¥ ìš”ì•½",\n'
            '  "reason": "íŒë‹¨ ê·¼ê±°",\n'
            '  "missing_criteria": ["ë¶€ì¡±í•œ ì¡°ê±´1", ...]\n'
            "}\n\n"
            f"ì‚¬ìš©ì ë‚˜ì´: {age_part}\n"
            f"ì‚¬ìš©ì ì§€ì—­: {region_part}\n\n"
            f"ì •ì±… ì œëª©: {policy.title}\n"
            f"ì •ì±… ì›ë¬¸(ì¼ë¶€):\n{text}\n"
        )
        return prompt

    @staticmethod
    def _parse_fast_track_result(raw: str) -> Dict[str, Any]:
        import json

        try:
            return json.loads(raw)
        except Exception:
            return {
                "badge_status": "WARNING",
                "short_summary": "ì •ì±… ìš”ì•½ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.",
                "reason": "LLM ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨",
                "missing_criteria": [],
            }

    @staticmethod
    def evaluate_eligibility(
        req: PolicySearchRequest,
        policy: Policy,
    ) -> Dict[str, Any]:
        """
        Fast Trackì—ì„œ ê° ì •ì±…ë³„ë¡œ PASS/WARNING/FAIL ë±ƒì§€ì™€ ìš”ì•½ì„ ë§Œë“œëŠ” í•¨ìˆ˜.
        - GOOGLE_API_KEY ì—†ìœ¼ë©´: ë°”ë¡œ ë”ë¯¸ ê²°ê³¼
        - LLM í˜¸ì¶œ ì¤‘ ì—ëŸ¬ ë‚˜ë©´: ë”ë¯¸ ê²°ê³¼ + ì—ëŸ¬ ì •ë³´ ì‚´ì§ í¬í•¨
        """
        # 1) í‚¤ê°€ ì•„ì˜ˆ ì—†ìœ¼ë©´: LLM ì—†ì´ ë”ë¯¸
        if not settings.google_api_key:
            return {
                "badge_status": BadgeStatus.PASS.value,
                "short_summary": f"{policy.title} (LLM ë¹„í™œì„±í™” ë”ë¯¸)",
                "reason": "GOOGLE_API_KEY ë¯¸ì„¤ì •",
                "missing_criteria": [],
            }

        prompt = LLMService._build_fast_track_prompt(req, policy)

        try:
            # ğŸ” ì—¬ê¸° ëª¨ë¸ ì´ë¦„ì€ í™˜ê²½ì— ë§ê²Œ ë‚˜ì¤‘ì— ì¡°ì • ê°€ëŠ¥
            #    ì¼ë‹¨ 404ê°€ ë‚˜ë„ exceptì—ì„œ ì²˜ë¦¬í•˜ë¯€ë¡œ ì„œë¹„ìŠ¤ëŠ” ì•ˆ ì£½ìŒ
            model = genai.GenerativeModel("gemini-1.5-flash-001")
            response = model.generate_content(prompt)
            raw_text = response.text or ""
            parsed = LLMService._parse_fast_track_result(raw_text)
            return parsed

        except Exception as e:
            # LLM í˜¸ì¶œ ì‹¤íŒ¨í•´ë„ FastAPIëŠ” 500 ì•ˆ ë‚´ê³ , ë±ƒì§€/ìš”ì•½ë§Œ ë”ë¯¸ë¡œ
            return {
                "badge_status": BadgeStatus.WARNING.value,
                "short_summary": f"{policy.title} (LLM ì˜¤ë¥˜ë¡œ ê°„ë‹¨ ìš”ì•½)",
                "reason": f"LLM í˜¸ì¶œ ì‹¤íŒ¨: {e.__class__.__name__}",
                "missing_criteria": [],
            }

    # ===== Deep Trackì—ì„œ ì‚¬ìš©í•  ì¶”ì¶œìš© =====
    @staticmethod
    def build_deep_track_prompt(page_texts: List[str]) -> str:
        combined = "\n\n---\n\n".join(page_texts)
        if len(combined) > 12000:
            combined = combined[:12000]

        prompt = (
            "ë‹¤ìŒì€ íŠ¹ì • ì²­ë…„ ì •ì±… í˜ì´ì§€ì—ì„œ ìˆ˜ì§‘í•œ í…ìŠ¤íŠ¸ì´ë‹¤.\n"
            "ì´ í…ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‹ ì²­ ìê²©/ëŒ€ìƒ/ê¸°ê°„/í•„ìˆ˜ ì„œë¥˜ ë“± ì¤‘ìš”í•œ ì¡°ê±´ì„ êµ¬ì¡°í™”í•´ë¼.\n\n"
            "ì‘ë‹µ í˜•ì‹ì€ ë°˜ë“œì‹œ JSON í•œ ì¤„ë¡œë§Œ ì¶œë ¥í•œë‹¤.\n"
            "{\n"
            '  "criteria": {\n'
            '    "age": "ì˜ˆ: ë§Œ 19~34ì„¸",\n'
            '    "region": "ì˜ˆ: ì„œìš¸ ê±°ì£¼",\n'
            '    "employment": "ì˜ˆ: ë¯¸ì·¨ì—… ë˜ëŠ” í”„ë¦¬ëœì„œ",\n'
            '    "others": ["ê¸°íƒ€ ì¡°ê±´1", "ê¸°íƒ€ ì¡°ê±´2", ...]\n'
            "  },\n"
            '  "evidence_text": "ê°€ì¥ í•µì‹¬ì ì¸ ë¶€ë¶„ë§Œ ë°œì·Œí•œ ìš”ì•½ í…ìŠ¤íŠ¸"\n'
            "}\n\n"
            "ë‹¤ìŒì€ ìˆ˜ì§‘ëœ ì›ë¬¸ì´ë‹¤:\n"
            f"{combined}\n"
        )
        return prompt

    @staticmethod
    def extract_verification_info(page_texts: List[str]) -> Dict[str, Any]:
        """
        Deep Trackì—ì„œ browser-use/Playwrightê°€ ìˆ˜ì§‘í•œ í…ìŠ¤íŠ¸ë“¤ì„ ê¸°ë°˜ìœ¼ë¡œ
        ìê²© ì¡°ê±´/ì¦ë¹™ í…ìŠ¤íŠ¸ë¥¼ êµ¬ì¡°í™”.
        """
        if not settings.google_api_key:
            return {
                "criteria": {
                    "age": "ì •ë³´ ì—†ìŒ",
                    "region": "ì •ë³´ ì—†ìŒ",
                    "employment": "ì •ë³´ ì—†ìŒ",
                    "others": [],
                },
                "evidence_text": "LLM ë¹„í™œì„±í™” ìƒíƒœ (ë”ë¯¸ ë°ì´í„°)",
            }

        prompt = LLMService.build_deep_track_prompt(page_texts)
        model = genai.GenerativeModel("gemini-1.5-flash")
        response = model.generate_content(prompt)
        raw = response.text or ""

        import json

        try:
            parsed = json.loads(raw)
        except Exception:
            parsed = {
                "criteria": {
                    "age": "íŒŒì‹± ì‹¤íŒ¨",
                    "region": "íŒŒì‹± ì‹¤íŒ¨",
                    "employment": "íŒŒì‹± ì‹¤íŒ¨",
                    "others": [],
                },
                "evidence_text": "LLM ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨",
            }
        return parsed
